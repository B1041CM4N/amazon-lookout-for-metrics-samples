{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting on Historical Data for Amazon Lookout for Metrics\n",
    "\n",
    "Amazon Lookout for Metrics supports backtesting against your historical information and in this notebook we will demonstrate this functionality on the same dataset you just prepped. Once the backtesting job has completed you can see all of the anomalies that Amazon Lookout for Metrics detected in the last 30% of your historical data. From here you can begin to unpack the kinds of results you will see from Amazon Lookout for Metrics in the future when you start streaming in new data. **NOTE YOU MUST CREATE A NEW DETECTOR TO LEVERAGE REAL TIME DATA. BACKTESTING IS ONLY FOR EXPLORATION.**\n",
    "\n",
    "This notebook assumes that you already completed the prerequisites in the `1.PrereqSetupPackages.ipynb` and `2.PrereqSetupData.ipynb`.If you have not, go back and complete those first.\n",
    "\n",
    "## Initial Steps\n",
    "\n",
    "First restore the variables from the previous notebook and then import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the last notebook, connect to AWS through the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IF THE CELL BELOW GENERATES AN ERROR:** This is totally normal, it may mean that your version of Boto3 is simply out of date. To correct this go to the cell below the one that errored and run it to update to the latest version of Boto3 inside SageMaker. IF you are not using a SageMaker Notebook simply follow the instructions for your Python environment. \n",
    "\n",
    "After running the upgrade cell, please click `Kernel` then `Restart Kernel` in the menu at the top. Once that has completed, start over at the top of this notebook again.\n",
    "\n",
    "**DO NOT RUN THE UPGRADE CELL UNLESS YOU NEED TO**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M = boto3.client( \"lookoutmetrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS OPTIONAL, DO NOT RUN IT IF YOU DO NOT NEED TO \n",
    "!pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Detector\n",
    "\n",
    "Now the basic external resources are ready, so it is time to get started with Amazon Lookout for Metrics, that starts with creating a `Detector`.\n",
    "\n",
    "### Detectors\n",
    "\n",
    "To detect outliers, Amazon Lookout for Metrics builds a machine learning model that is trained with your source data. This model, called a `Detector`, is automatically trained with the machine learning algorithm that best fits your data and use case. You can either provide your historical data for training, if you have any, or get started with real-time data, and Amazon Lookout for Metrics will learn on-the-go. In this example for `Backtesting` you will only be providing historical data.\n",
    "\n",
    "Here you will specify the S3 location of the historicla data, however you could specify the Amazon S3 location that Amazon Lookout for Metrics would continuously monitor for new data if you were creating a `Continous` detector. When you create a `Detector`, you also specify a `detecting domain` and an `outlier detection frequency`. \n",
    "\n",
    "The `anomaly detection frequency` specifies how frequently the detector should wake-up and look for new data, run analysis and alert you with any interesting findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"initial-lookoutmetrics-backtesting-test\"\n",
    "\n",
    "frequency = \"PT1H\" # one of 'P1D', 'PT1H', 'PT10M' and 'PT5M', this one means every one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_anomaly_detector( \n",
    "    AnomalyDetectorName = project + \"-detector\",\n",
    "    AnomalyDetectorDescription = \"My Detector\",\n",
    "    AnomalyDetectorConfig = {\n",
    "        \"AnomalyDetectorFrequency\" : \"PT1H\",\n",
    "    },\n",
    ")\n",
    "\n",
    "anomaly_detector_arn = response[\"AnomalyDetectorArn\"]\n",
    "anomaly_detector_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metrics\n",
    "\n",
    "### Measures and Dimensions\n",
    "\n",
    "`Measures` are variables or key performance indicators on which customers want to detect outliers and `Dimensions` are meta-data that represent categorical information about the measures. \n",
    "\n",
    "In this E-commerce example, views and revenue are our measures and platform and marketplace are our dimensions. Customers may want to monitor their data for anomalies in number of views or revenue for every platform, marketplace, and combination of both. You can designate up to five measures and five dimensions per dataset.\n",
    "\n",
    "### Metrics \n",
    "\n",
    "\n",
    "After creating a detector, and mapping your measures and dimensions, Amazon Lookout for Metrics will analyze each combination of these measures and dimensions. For the above example, you have of 7 unique values (us, jp, de, etc.) for marketplace and 3 unique values (mobile web, mobile app, pc web) for platform for a total of 21 unique combinations. Each unique combination of measures with the dimension values (e.g. us/mobile app/revenue) is a time series `metric`. In this case, you have 21 dimensions and 2 measures for a total of 42 time-series `metrics`. \n",
    "\n",
    "Amazon Lookout for Metrics detects anomalies at the most granular level so you are able to pin-point any unexpected behavior in your data.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "Measures, dimensions and metrics map to `datasets`, which also contain the Amazon S3 locations of your source data, an IAM role that has both read and write permissions to those Amazon S3 locations, and the rate at which data should be ingested from the source location (the upload frequency and data ingestion delay).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a metric set for our detector that point to the backtest data in S3:\n",
    "\n",
    "First, the cell below will create a backtesting path for S3 which is then passed to our arguments and then the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_backtest = 's3://'+ s3_bucket + '/ecommerce/backtest/'\n",
    "s3_path_backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"AnomalyDetectorArn\": anomaly_detector_arn,\n",
    "    \"MetricSetName\" : project + '-metric-set-1',\n",
    "    \"MetricList\" : [\n",
    "        {\n",
    "            \"MetricName\" : \"views\",\n",
    "            \"AggregationFunction\" : \"SUM\",\n",
    "        },\n",
    "        {\n",
    "            \"MetricName\" : \"revenue\",\n",
    "            \"AggregationFunction\" : \"SUM\",\n",
    "        },\n",
    "    ],\n",
    "\n",
    "    \"DimensionList\" : [ \"platform\", \"marketplace\" ],\n",
    "\n",
    "    \"TimestampColumn\" : {\n",
    "        \"ColumnName\" : \"timestamp\",\n",
    "        \"ColumnFormat\" : \"yyyy-MM-dd HH:mm:ss\",\n",
    "    },\n",
    "\n",
    "    #\"Delay\" : 120, # seconds the detector will wait before attempting to read latest data per current time and detection frequency below\n",
    "    \"MetricSetFrequency\" : frequency,\n",
    "\n",
    "    \"MetricSource\" : {\n",
    "        \"S3SourceConfig\": {\n",
    "            \"RoleArn\" : role_arn,\n",
    "            \"HistoricalDataPathList\": [\n",
    "                s3_path_backtest,\n",
    "            ],\n",
    "#            \"TemplatedPathList\": [\n",
    "#                s3_path_format,\n",
    "#            ],\n",
    "\n",
    "            \"FileFormatDescriptor\" : {\n",
    "                \"CsvFormatDescriptor\" : {\n",
    "                    \"FileCompression\" : \"NONE\",\n",
    "                    \"Charset\" : \"UTF-8\",\n",
    "                    \"ContainsHeader\" : True,\n",
    "                    \"Delimiter\" : \",\",\n",
    "#                    \"HeaderList\" : [\n",
    "#                        \"platform\",\n",
    "#                        \"marketplace\",\n",
    "#                        \"timestamp\",\n",
    "#                        \"views\",\n",
    "#                        \"revenue\"\n",
    "#                    ],\n",
    "                    \"QuoteSymbol\" : '\"'\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will take those arguments and create our `MetricSet` so we are ready to activate in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = L4M.create_metric_set( ** params )\n",
    "\n",
    "metric_set_arn = response[\"MetricSetArn\"]\n",
    "metric_set_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the Detector and Execute Backtesting\n",
    "\n",
    "Now that the `MetricSet` has been specified, you are ready to start backtesting, that's done by activating the back test anomaly detector. The backtesting process can take 25 minutes or so, so feel free to take a break and grab a snack and catch up on any articles you have saved. Note, when it says `BACK_TEST_ACTIVE` the service has trained a model and is now evaluating the holdout period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L4M.back_test_anomaly_detector(AnomalyDetectorArn = anomaly_detector_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the cell will first report that it is activating, then that the backtesting job is active. This merely means that it is executing the inference process, give it more time until the cell fully completes before looking for anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.wait_anomaly_detector( L4M, anomaly_detector_arn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate results\n",
    "\n",
    "After backtesting is finished, you can visually validate the historical anomalies via the console or inspect the results by running the commands below. It is recommended that you start your exploration in the console however. The console will be your tool for viewing and understanding alerts in the online mode later, this way you start to get familiar with the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_groups = []\n",
    "next_token = None\n",
    "first_response = None\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"AnomalyDetectorArn\" : anomaly_detector_arn,\n",
    "        \"SensitivityThreshold\" : 50,\n",
    "        \"MaxResults\" : 100,\n",
    "    }\n",
    "    \n",
    "    if next_token:\n",
    "        params[\"NextToken\"] = next_token\n",
    "    \n",
    "    response = L4M.list_anomaly_group_summaries( **params )\n",
    "    if first_response is None:\n",
    "        first_response = response\n",
    "    \n",
    "    anomaly_groups += response[\"AnomalyGroupSummaryList\"]\n",
    "    \n",
    "    if \"NextToken\" in response:\n",
    "        next_token = response[\"NextToken\"]\n",
    "        continue\n",
    "    break\n",
    "\n",
    "first_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to dive even deeper into a specific anomaly group, simlpy choose your anomaly group of interest and drill down to it's time-series. Here you will use the first anomaly group in the list.\n",
    "\n",
    "\n",
    "## Exporting Results\n",
    "\n",
    "To do that, simply open `4.ExportingAnomalies.ipynb` and it will guide you through creating a CSV file of all the anomalies found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources \n",
    "\n",
    "Once you have completed backtesting, you can start to cleanup the resources that were created. Before cleaning up, you can visit the \"Anomalies\" page of the Amazon Lookout for Metrics console, and visually check the detected anomalies.\n",
    "\n",
    "Note this will erase all the resources that have been created, so wait to run this until you are sure you wish to delete everything.\n",
    "\n",
    "**NOTE IF YOU DELETE THE ROLE BELOW YOU NEED TO CREATE IT AGAIN BEFORE YOU CAN BUILD THE CONTINOUS DETECTOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = input(\"Delete resources? (y/n)\")\n",
    "if answer==\"y\":\n",
    "    delete_resources = True\n",
    "else:\n",
    "    delete_resources = False\n",
    "    \n",
    "if delete_resources:\n",
    "    L4M.delete_anomaly_detector( AnomalyDetectorArn = anomaly_detector_arn )\n",
    "    utility.wait_delete_anomaly_detector( L4M, anomaly_detector_arn )\n",
    "    utility.delete_iam_role(role_name)\n",
    "else:\n",
    "    print(\"Not deteleting resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
